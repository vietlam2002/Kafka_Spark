{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Khởi tạo SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "            .appName('SparkDataStreaming') \\\n",
    "            .config('spark.jars.packages', \"com.datastax.spark:spark-cassandra-connector_2.12:3.5.0,\"\n",
    "                                           \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.2\") \\\n",
    "            .config('spark.cassandra.connection.host', 'cassandra') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ Kafka topic\n",
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka1:29092,kafka2:29092,kafka3:29092\") \\\n",
    "  .option(\"subscribe\", \"users_created\") \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['cassandra'])\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "        StructField(\"id\", StringType(), False),\n",
    "        StructField(\"first_name\", StringType(), False),\n",
    "        StructField(\"last_name\", StringType(), False),\n",
    "        StructField(\"gender\", StringType(), False),\n",
    "        StructField(\"address\", StringType(), False),\n",
    "        StructField(\"post_code\", StringType(), False),\n",
    "        StructField(\"email\", StringType(), False),\n",
    "        StructField(\"username\", StringType(), False),\n",
    "        StructField(\"registered_date\", StringType(), False),\n",
    "        StructField(\"phone\", StringType(), False),\n",
    "        StructField(\"picture\", StringType(), False)\n",
    "    ])\n",
    "\n",
    "sel = df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "        .select(from_json(col('value'), schema).alias('data')).select(\"data.*\")\n",
    "print(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export result\n",
    "# query = sel \\\n",
    "#     .writeStream \\\n",
    "#     .outputMode(\"append\") \\\n",
    "#     .format(\"csv\") \\\n",
    "#     .option(\"header\", \"true\") \\\n",
    "#     .option(\"checkpointLocation\", \"work\") \\\n",
    "#     .option(\"path\", \"work/da.csv\") \\\n",
    "#     .start()\n",
    "\n",
    "# query.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_query = (sel.writeStream.format(\"org.apache.spark.sql.cassandra\")\n",
    "                               .option('checkpointLocation', '/tmp/checkpoint')\n",
    "                               .options(keyspace='spark_streams', table='created_users')\n",
    "                               .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
